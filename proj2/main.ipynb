{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b9f4357",
   "metadata": {},
   "source": [
    "## Main Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f651a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8727b43c",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7a4e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train  = pd.read_csv(\"data/train.csv\")\n",
    "df_sample = pd.read_csv(\"data/sample_submission.csv\")\n",
    "df_test   = pd.read_csv(\"data/train.csv\")\n",
    "\n",
    "labels = ['Insufficient_Weight', 'Normal_Weight', 'Obesity_Type_I', 'Obesity_Type_II', 'Obesity_Type_III' , 'Overweight_Level_I', 'Overweight_Level_II']\n",
    "\n",
    "# drop id (not useful)\n",
    "df_train.drop('id',axis=1,inplace=True)\n",
    "df_test.drop('id',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86d493b",
   "metadata": {},
   "source": [
    "## Response Factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f3ecf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "class Response:\n",
    "  def __init__(self, predictions, features, predict_proba, start_time):\n",
    "    self.predictions = predictions\n",
    "    self.features = features\n",
    "    self.predict_proba = predict_proba\n",
    "    self.execution_time = time.time() - start_time\n",
    "    \n",
    "  def get_predictions(self): return self.predictions\n",
    "  \n",
    "  def get_features(self): return self.features\n",
    "  \n",
    "  def get_time(self): return self.execution_time\n",
    "  \n",
    "  def get_predict_proba(self): return self.predict_proba\n",
    "  \n",
    "  def get_stats(self):\n",
    "    print_stats(self.get_predictions(), self.get_features(), self.get_time())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0482547f",
   "metadata": {},
   "source": [
    "## Additional Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0662f4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['BMI'] = (df_train['Weight'] / df_train['Height']**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eab6ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols   = df_train.select_dtypes(include=['int64','float64']).columns.tolist()\n",
    "categorical_cols = df_train.select_dtypes(include=[object]).columns.tolist()\n",
    "\n",
    "num_numerical_cols = len(numerical_cols)\n",
    "num_numerical_rows = num_numerical_cols // 4\n",
    "\n",
    "num_categorical_cols = len(categorical_cols)\n",
    "num_categorical_rows = num_categorical_cols // 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29785ecf",
   "metadata": {},
   "source": [
    "## Data Spliting and Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef2eff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, label_binarize\n",
    "\n",
    "y = df_train['NObeyesdad']\n",
    "x = df_train.copy().drop(columns=['NObeyesdad'])\n",
    "\n",
    "categoricals_cols_no_result = [col for col in categorical_cols if col != \"NObeyesdad\"]\n",
    "x = pd.get_dummies(x, columns=categoricals_cols_no_result, drop_first=True)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.20)\n",
    "\n",
    "y_test_bin = label_binarize(y_test, classes=labels)\n",
    "n_classes = y_test_bin.shape[1]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3adca4",
   "metadata": {},
   "source": [
    "## Stats Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073300d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,confusion_matrix,ConfusionMatrixDisplay\n",
    "import time\n",
    "\n",
    "def print_stats(predictions, features, time):\n",
    "  print(\"Accuracy Score: \" + str(round(accuracy_score(y_test, predictions), 4) * 100) + \"%\")\n",
    "  print(\"Precision Score: \" + str(round(precision_score(y_test, predictions, average=\"macro\"), 4) * 100) + \"%\")\n",
    "  print(\"Recall Score: \" + str(round(recall_score(y_test, predictions, average='macro'), 4) * 100) + \"%\")\n",
    "  print(\"F1 Score: \" + str(round(f1_score(y_test,predictions, average='macro'), 2) * 100) + \"%\")\n",
    "  if(len(features) > 0): print(\"Selected Features: \" + ','.join(features))\n",
    "  print(\"Execution Time: \" + str(round(time, 2)) + \"s\")\n",
    "  \n",
    "  cm = confusion_matrix(y_test, predictions, labels=labels)\n",
    "  \n",
    "  ConfusionMatrixDisplay(cm).plot()\n",
    "  \n",
    "def print_time(start):\n",
    "  print(\"Time spent: \" + str(round(time.time() - start, 4)) + \"s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500b509c",
   "metadata": {},
   "source": [
    "## Duplicate and NA Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d251f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of na\n",
    "mv = df_train.isna().sum().sum()\n",
    "\n",
    "# number of duplicates\n",
    "dv = df_train.duplicated().sum()\n",
    "\n",
    "# there are no NAs or Duplicates in the test dataset\n",
    "print(mv)\n",
    "print(dv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260f8eba",
   "metadata": {},
   "source": [
    "## Features Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95071454",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_train.describe(include=[np.number]).T, df_train.describe(include=[object]).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69981dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerical cols histogram\n",
    "plt.figure(figsize=(20,6 * num_numerical_rows))\n",
    "for i ,col in enumerate(numerical_cols,1):\n",
    "    plt.subplot(num_numerical_rows, 5, i)\n",
    "    plt.hist(df_train[col])\n",
    "    plt.title(f'{col} Distribution')\n",
    "    plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d35ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical cols histogram\n",
    "plt.figure(figsize=(20,6 * num_categorical_rows))\n",
    "for i ,col in enumerate(categorical_cols,1):\n",
    "    plt.subplot(num_categorical_rows, 5, i)\n",
    "    plt.hist(df_train[col])\n",
    "    plt.title(f'{col} Distribution')\n",
    "    plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3761faff",
   "metadata": {},
   "source": [
    "## Feature Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ae9fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr(data):\n",
    "    plt.figure(figsize=(12,10))\n",
    "    sns.heatmap(data, annot=True, cmap='coolwarm', fmt='.2f', linewidths= 0.5)\n",
    "    plt.title('Correlation Matrix of Features')\n",
    "corr(df_train[numerical_cols].corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5909ab20",
   "metadata": {},
   "source": [
    "## Parameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b81262",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a952e12",
   "metadata": {},
   "source": [
    "### Without FS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733dd17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import time\n",
    "\n",
    "def decision_tree_wfs() -> Response:\n",
    "  start = time.time()\n",
    "\n",
    "  model = DecisionTreeClassifier(ccp_alpha=0.01)\n",
    "  predictions = model.fit(x_train_scaled, y_train).predict(x_test_scaled)\n",
    "  predicted_proba = model.predict_proba(x_test_scaled)\n",
    "\n",
    "  return Response(predictions, [], predicted_proba, start)\n",
    "\n",
    "  # feature_importance = pd.DataFrame(clf.feature_importances_, index = x.columns).sort_values(0, ascending=False)\n",
    "  # feature_importance.head(10).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038cdda9",
   "metadata": {},
   "source": [
    "### With FS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36b837f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import time\n",
    "\n",
    "def decision_tree_fs() -> Response:\n",
    "  start = time.time()\n",
    "  \n",
    "  clf = DecisionTreeClassifier(ccp_alpha=0.01)\n",
    "  \n",
    "  max_acc = 0\n",
    "  max_features = x.shape[1]\n",
    "  best_features_names = None\n",
    "  best_predictions = None\n",
    "  best_proba = None\n",
    "\n",
    "  for i in range(1,max_features):\n",
    "    rfe = RFE(estimator=clf, n_features_to_select=i).fit(x_train_scaled, y_train)\n",
    "\n",
    "    selected_features = x_train.columns[rfe.support_]\n",
    "\n",
    "    x_train_rfe = rfe.transform(x_train_scaled)\n",
    "    x_test_rfe = rfe.transform(x_test_scaled)\n",
    "\n",
    "    clf.fit(x_train_rfe, y_train)\n",
    "    predictions = clf.predict(x_test_rfe)\n",
    "    predicted_proba = clf.predict_proba(x_test_rfe)\n",
    "\n",
    "    acc = accuracy_score(y_test, predictions)\n",
    "    \n",
    "    if(acc > max_acc): # From 3 features beyond the accuracy does not change\n",
    "      max_acc = acc\n",
    "      best_features_names = selected_features\n",
    "      best_predictions = predictions\n",
    "      best_proba = predicted_proba\n",
    "    \n",
    "  return Response(best_predictions, best_features_names, best_proba, start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1791adda",
   "metadata": {},
   "source": [
    "## K-Nearest-Neighbours"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41abc662",
   "metadata": {},
   "source": [
    "### Finding Optimal K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c07a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "\n",
    "number_of_runs = 20\n",
    "number_of_neighbors = 25\n",
    "\n",
    "top_k_counts = Counter()\n",
    "k_accuracy_map = defaultdict(list)\n",
    "\n",
    "for run in range(1, number_of_runs + 1):\n",
    "    k_accuracies = []\n",
    "\n",
    "    for k in range(1, number_of_neighbors + 1):\n",
    "        knn = KNeighborsClassifier(n_neighbors=k)\n",
    "        knn.fit(x_train_scaled, y_train)\n",
    "        preds = knn.predict(x_test_scaled)\n",
    "        acc = accuracy_score(y_test, preds)\n",
    "        k_accuracies.append((k, acc))\n",
    "\n",
    "    k_accuracies.sort(key=lambda tup: tup[1], reverse=True)\n",
    "    \n",
    "    for i, (k, acc) in enumerate(k_accuracies):\n",
    "        k_accuracy_map[k].append(acc)\n",
    "        if i == 0:\n",
    "            top_k_counts[k] += 1\n",
    "\n",
    "    best_k, best_acc = k_accuracies[0]\n",
    "\n",
    "avg_accuracies = {k: np.mean(accs) for k, accs in k_accuracy_map.items()}\n",
    "sorted_avg = sorted(avg_accuracies.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "best_avg_k, best_avg_acc = sorted_avg[0]\n",
    "print(f\"\\nBest k by average accuracy: k = {best_avg_k}\\n\")\n",
    "\n",
    "ks = sorted(avg_accuracies.keys())\n",
    "accs = [avg_accuracies[k] for k in ks]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(ks, accs, marker='o')\n",
    "plt.title(\"Average Accuracy for each k\")\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"Average Accuracy\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ed84b0",
   "metadata": {},
   "source": [
    "### Without FS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a8cc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import time\n",
    "\n",
    "def knn_wfs(num_neighbours) -> Response:\n",
    "  start = time.time()\n",
    "  \n",
    "  model = KNeighborsClassifier(n_neighbors=num_neighbours)\n",
    "  model.fit(x_train_scaled, y_train)\n",
    "  predictions = model.predict(x_test_scaled)\n",
    "  predicted_proba = model.predict_proba(x_test_scaled)\n",
    "  \n",
    "  return Response(predictions, [], predicted_proba, start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084f2706",
   "metadata": {},
   "source": [
    "### With FS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc98c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "import time\n",
    "\n",
    "def knn_fs(neighbour_number) -> Response:\n",
    "  start = time.time()\n",
    "  \n",
    "  max_acc = 0\n",
    "  max_features = x.shape[1]\n",
    "  best_features_names = None\n",
    "  best_predictions = None\n",
    "  best_proba = None\n",
    "  \n",
    "  knn = KNeighborsClassifier(n_neighbors=neighbour_number)\n",
    "\n",
    "  for i in range(1, max_features):\n",
    "    sfs = RFE(\n",
    "        estimator=knn,\n",
    "        n_features_to_select=i, \n",
    "        step=1\n",
    "    ).fit(x_train_scaled, y_train)\n",
    "\n",
    "    selected_features = x_train.columns[sfs.get_support()]\n",
    "\n",
    "    x_train_sfs = sfs.transform(x_train_scaled)\n",
    "    x_test_sfs = sfs.transform(x_test_scaled)\n",
    "\n",
    "    knn.fit(x_train_sfs, y_train)\n",
    "\n",
    "    predictions = knn.predict(x_test_sfs)\n",
    "    predicted_proba = knn.predict_proba(x_test_sfs)\n",
    "    acc = accuracy_score(y_test, predictions)\n",
    "\n",
    "    if(acc > max_acc):\n",
    "      max_acc = acc\n",
    "      best_predictions = predictions\n",
    "      best_features_names = selected_features\n",
    "      best_proba = predicted_proba\n",
    "      \n",
    "  return Response(best_predictions, best_features_names, best_proba, start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb8c49f",
   "metadata": {},
   "source": [
    "## Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5a3fec",
   "metadata": {},
   "source": [
    "### Without FS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5354ba9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "import time\n",
    "\n",
    "def svc_wfs() -> Response:\n",
    "  start = time.time()\n",
    "  model = SVC(probability=True)\n",
    "  model.fit(x_train_scaled, y_train)\n",
    "  predictions = model.predict(x_test_scaled)\n",
    "  predicted_proba = model.predict_proba(x_test_scaled)\n",
    "\n",
    "  return Response(predictions, [], predicted_proba, start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06ccad2",
   "metadata": {},
   "source": [
    "### With FS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81e5761",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "import time \n",
    "\n",
    "def svc_fs() -> Response:\n",
    "  start = time.time()\n",
    "  \n",
    "  print(\"fitting\")\n",
    "  svc = SVC(kernel=\"linear\", probability=True)\n",
    "  print(\"fitted\")\n",
    "  \n",
    "  max_acc = 0\n",
    "  best_features_names = None\n",
    "  max_features = x.shape[1]\n",
    "  best_predictions = None\n",
    "  best_proba = None\n",
    "\n",
    "  for i in range(1,max_features):\n",
    "    print(\"sfs\")\n",
    "    sfs = RFE(\n",
    "        estimator=svc,\n",
    "        n_features_to_select=i, \n",
    "        step=1\n",
    "    ).fit(x_train_scaled, y_train)\n",
    "    \n",
    "    selected_features = x_train.columns[sfs.get_support()]\n",
    "    print(\"Selected features: \" + str(selected_features))\n",
    "    \n",
    "    x_train_sfs = sfs.transform(x_train_scaled)\n",
    "    x_test_sfs = sfs.transform(x_test_scaled)\n",
    "\n",
    "    svc.fit(x_train_sfs, y_train)\n",
    "\n",
    "    predictions = svc.predict(x_test_sfs)\n",
    "    predicted_proba = svc.predict_proba(x_test_sfs)\n",
    "    acc = accuracy_score(y_test, predictions)\n",
    "\n",
    "    if(acc > max_acc):\n",
    "      max_acc = acc\n",
    "      best_predictions = predictions\n",
    "      best_features_names = selected_features\n",
    "      best_proba = predicted_proba\n",
    "      \n",
    "  return Response(best_predictions, best_features_names, best_proba, start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a613490",
   "metadata": {},
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca36053",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "def neural_networks() -> Response:\n",
    "    start = time.time()\n",
    "    \n",
    "    label_encoder = LabelEncoder()\n",
    "    y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "    y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "    model = MLPClassifier(\n",
    "        hidden_layer_sizes=(128, 64, 32),\n",
    "        activation='relu',\n",
    "        solver='adam',                    \n",
    "        alpha=0.0001,                      \n",
    "        batch_size='auto',\n",
    "        learning_rate='adaptive',         \n",
    "        max_iter=1000,                     \n",
    "        early_stopping=True,               \n",
    "        validation_fraction=0.2,          \n",
    "        n_iter_no_change=10,          \n",
    "    )\n",
    "    \n",
    "    model.fit(x_train_scaled, y_train_encoded)\n",
    "    predictions_encoded = model.predict(x_test_scaled)\n",
    "    predicted_proba = model.predict_proba(x_test_scaled)\n",
    "    \n",
    "    predictions = label_encoder.inverse_transform(predictions_encoded)\n",
    "\n",
    "    mse = mean_squared_error(y_test_encoded, predictions_encoded)\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.scatter(y_test_encoded, predictions_encoded, alpha=0.5, color=\"red\", label=\"Predicted\")\n",
    "    plt.scatter(y_test_encoded, y_test_encoded, alpha=0.5, color='blue', label='Actual')\n",
    "    plt.plot(y_test_encoded, y_test_encoded, color='green', linewidth=2)\n",
    "    plt.title('Neural Network Predicted vs. Actual Values')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return Response(predictions, [], predicted_proba, start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2162adf0",
   "metadata": {},
   "source": [
    "## ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9700d763",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "def ROC(response):\n",
    "\n",
    "  for i in range(n_classes):\n",
    "      RocCurveDisplay.from_predictions(\n",
    "          y_test_bin[:, i],\n",
    "          response.get_predict_proba()[:, i],\n",
    "          name=f\"DT - Class {i}\",\n",
    "      )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae4546d",
   "metadata": {},
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e7d607",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "clf = DecisionTreeClassifier(ccp_alpha=0.01)\n",
    "knn = KNeighborsClassifier(n_neighbors=6)\n",
    "mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(250, 150, 100),\n",
    "    activation='relu',\n",
    "    solver='adam',                    \n",
    "    alpha=0.0001,                      \n",
    "    batch_size='auto',\n",
    "    learning_rate='adaptive',         \n",
    "    max_iter=1000,                     \n",
    "    early_stopping=True,               \n",
    "    validation_fraction=0.2,          \n",
    "    n_iter_no_change=10,          \n",
    ")\n",
    "svc = SVC()\n",
    "\n",
    "ensemble = VotingClassifier(estimators=[(\"clf\", clf), (\"knn\", knn), (\"mlp\", mlp), (\"svc\", svc)], voting=\"hard\")\n",
    "\n",
    "ensemble.fit(x_train_scaled, y_train)\n",
    "print(f\"Accuracy of the ensemble: {round(ensemble.score(x_test_scaled, y_test)*100, 2)} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0afb3c",
   "metadata": {},
   "source": [
    "## TESTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1deec8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision_tree_wfs().get_stats() # 85.21\n",
    "# decision_tree_fs().get_stats() # 85.21\n",
    "\n",
    "ROC(decision_tree_wfs())\n",
    "\n",
    "# knn_wfs(8).get_stats() # 78.47\n",
    "# knn_fs(8).get_stats() # 87.14\n",
    "\n",
    "# svc_wfs().get_stats() # 87.24\n",
    "# svc_fs().get_stats() # 87.52\n",
    "\n",
    "# neural_networks().get_stats() # 88.32%\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
